{
  "id": "c-day66-ex02-ft-token-list",
  "category": "c",
  "day": 66,
  "order": 2,
  "title": "Stocker les tokens dans une liste chainee",
  "description": "Ecris les fonctions pour stocker les tokens dans une liste chainee de t_token. Chaque t_token contient un type (enum e_token_type), une valeur (char *value), et un pointeur next. Ecris ft_token_new pour creer un token, ft_token_add pour l'ajouter en fin de liste, et ft_token_free pour liberer la liste.",
  "difficulty": 5,
  "points": 50,
  "estimatedTime": 40,
  "learningObjectives": [
    "Definir une structure t_token avec type, valeur et pointeur next",
    "Creer une liste chainee de tokens a partir d'une ligne de commande",
    "Implementer l'ajout en fin de liste chainee",
    "Liberer correctement toute la liste de tokens",
    "Combiner tokenisation, classification et stockage en liste"
  ],
  "learningContent": {
    "lesson": {
      "introduction": "Cet exercice fait partie de l'introduction au projet minishell, l'un des projets les plus importants du cursus 42. Ecris les fonctions pour stocker les tokens dans une liste chainee de t_token. Chaque t_token contient un type (enum e_token_type), une valeur (char *value), et un pointeur next. Ecris ft_token_new pour creer un token, ft_token_add pour l'ajouter en fin de liste, et ft_token_free pour liberer la liste.",
      "steps": [
        {
          "id": 1,
          "title": "Comprendre le probleme",
          "content": "L'objectif est de stocker les tokens dans une liste chainee. C'est une etape fondamentale du traitement des commandes shell.",
          "codeExample": "// Exemple d'utilisation :\n// Entree : \"ls -la | grep test > output.txt\"\n// Sortie attendue depend de l'exercice",
          "language": "c",
          "tryItYourself": {
            "instruction": "Identifie les tokens dans la commande 'echo hello > file.txt'.",
            "starterCode": "// Commande : echo hello > file.txt\n// Token 1 : ???\n// Token 2 : ???\n// Token 3 : ???\n// Token 4 : ???",
            "solution": "// Token 1 : 'echo' (WORD)\n// Token 2 : 'hello' (WORD)\n// Token 3 : '>' (REDIR_OUT)\n// Token 4 : 'file.txt' (WORD)"
          }
        },
        {
          "id": 2,
          "title": "Algorithme principal",
          "content": "L'algorithme parcourt la chaine caractere par caractere, identifie les limites de chaque token, et les stocke dans la structure appropriee.",
          "codeExample": "// Pseudo-code :\n// i = 0\n// while (line[i])\n//   skip_spaces()\n//   if (is_operator(line[i]))\n//     extract_operator()\n//   else\n//     extract_word()\n//   add_token()",
          "language": "c",
          "tryItYourself": {
            "instruction": "Que doit faire la fonction quand elle rencontre un espace ?",
            "starterCode": "// Quand line[i] est un espace :\n// Action : ???",
            "solution": "// Quand line[i] est un espace :\n// On skip tous les espaces consecutifs\n// while (line[i] == ' ') i++;\n// Puis on continue avec le prochain token"
          }
        },
        {
          "id": 3,
          "title": "Gestion des cas speciaux",
          "content": "Les cas speciaux incluent les operateurs multi-caracteres (>>), les chaines entre guillemets, et les lignes vides. Chaque cas doit etre gere explicitement.",
          "codeExample": "// Operateur >> :\nif (line[i] == '>' && line[i + 1] == '>')\n{\n\t// Token = \">>\"\n\ti += 2;\n}\nelse if (line[i] == '>')\n{\n\t// Token = \">\"\n\ti += 1;\n}",
          "language": "c",
          "tryItYourself": {
            "instruction": "Comment distinguer > de >> dans la chaine ?",
            "starterCode": "// line = \"echo test >> file\"\n// Position du premier > : i = ???\n// Comment savoir si c'est >> : ???",
            "solution": "// Quand on trouve '>' a position i :\n// Verifier line[i + 1]\n// Si line[i+1] == '>' : c'est >> (avancer de 2)\n// Sinon : c'est > (avancer de 1)"
          }
        },
        {
          "id": 4,
          "title": "Solution complete",
          "content": "La solution complete combine le parcours de la chaine, l'identification des tokens, et leur stockage. La cle est de bien gerer chaque type de caractere rencontre.",
          "codeExample": "// Structure generale :\n// 1. Initialiser la structure de resultat\n// 2. Parcourir la chaine\n// 3. Pour chaque caractere :\n//    - Espace : skip\n//    - Operateur : extraire et ajouter\n//    - Autre : extraire le mot et ajouter\n// 4. Retourner le resultat",
          "language": "c"
        }
      ]
    },
    "theory": [
      {
        "title": "Listes chainees de tokens",
        "content": "Une liste chainee est ideale pour stocker les tokens car le nombre de tokens est inconnu a l'avance. Chaque noeud contient un token et un pointeur vers le suivant.",
        "codeExamples": [
          {
            "title": "Exemple : Listes chainees de tokens",
            "code": "// Illustration de : Listes chainees de tokens\n// Voir les exemples dans la lecon",
            "explanation": "Ce concept est central pour stocker les tokens dans une liste chainee."
          }
        ],
        "keyPoints": [
          "Concept cle 1 pour listes chainees de tokens",
          "Concept cle 2 pour listes chainees de tokens",
          "Concept cle 3 pour listes chainees de tokens",
          "Concept cle 4 pour listes chainees de tokens"
        ],
        "commonMistakes": [
          "Erreur courante 1 en listes chainees de tokens",
          "Erreur courante 2 en listes chainees de tokens",
          "Erreur courante 3 en listes chainees de tokens"
        ]
      },
      {
        "title": "Ajout en fin de liste",
        "content": "L'ajout en fin de liste (append) necessite de parcourir toute la liste pour trouver le dernier element. Alternative : garder un pointeur vers la queue.",
        "codeExamples": [
          {
            "title": "Exemple : Ajout en fin de liste",
            "code": "// Illustration de : Ajout en fin de liste\n// Voir les exemples dans la lecon",
            "explanation": "Ce concept est central pour stocker les tokens dans une liste chainee."
          }
        ],
        "keyPoints": [
          "Concept cle 1 pour ajout en fin de liste",
          "Concept cle 2 pour ajout en fin de liste",
          "Concept cle 3 pour ajout en fin de liste",
          "Concept cle 4 pour ajout en fin de liste"
        ],
        "commonMistakes": [
          "Erreur courante 1 en ajout en fin de liste",
          "Erreur courante 2 en ajout en fin de liste",
          "Erreur courante 3 en ajout en fin de liste"
        ]
      },
      {
        "title": "Liberation d'une liste de tokens",
        "content": "La liberation parcourt la liste et libere chaque noeud : d'abord la valeur (strdup), puis le noeud. Pattern classique avec sauvegarde de next.",
        "codeExamples": [
          {
            "title": "Exemple : Liberation d'une liste de tokens",
            "code": "// Illustration de : Liberation d'une liste de tokens\n// Voir les exemples dans la lecon",
            "explanation": "Ce concept est central pour stocker les tokens dans une liste chainee."
          }
        ],
        "keyPoints": [
          "Concept cle 1 pour liberation d'une liste de tokens",
          "Concept cle 2 pour liberation d'une liste de tokens",
          "Concept cle 3 pour liberation d'une liste de tokens",
          "Concept cle 4 pour liberation d'une liste de tokens"
        ],
        "commonMistakes": [
          "Erreur courante 1 en liberation d'une liste de tokens",
          "Erreur courante 2 en liberation d'une liste de tokens",
          "Erreur courante 3 en liberation d'une liste de tokens"
        ]
      },
      {
        "title": "Pipeline de traitement",
        "content": "La tokenisation est la premiere etape d'un pipeline : tokeniser -> classifier -> parser -> executer. Chaque etape produit une structure plus raffinee.",
        "codeExamples": [
          {
            "title": "Exemple : Pipeline de traitement",
            "code": "// Illustration de : Pipeline de traitement\n// Voir les exemples dans la lecon",
            "explanation": "Ce concept est central pour stocker les tokens dans une liste chainee."
          }
        ],
        "keyPoints": [
          "Concept cle 1 pour pipeline de traitement",
          "Concept cle 2 pour pipeline de traitement",
          "Concept cle 3 pour pipeline de traitement",
          "Concept cle 4 pour pipeline de traitement"
        ],
        "commonMistakes": [
          "Erreur courante 1 en pipeline de traitement",
          "Erreur courante 2 en pipeline de traitement",
          "Erreur courante 3 en pipeline de traitement"
        ]
      }
    ],
    "prepExercises": [
      {
        "id": 1,
        "title": "Skip les espaces",
        "instruction": "Ecris une fonction qui avance l'index pour sauter les espaces.",
        "starterCode": "void skip_spaces(char *line, int *i)\n{\n\t// Avance *i tant que line[*i] est un espace\n}",
        "solution": "void skip_spaces(char *line, int *i)\n{\n\twhile (line[*i] == ' ' || line[*i] == '\\t')\n\t\t(*i)++;\n}",
        "hint": "Boucle while avec espace et tabulation.",
        "difficulty": 1
      },
      {
        "id": 2,
        "title": "Detecter un operateur",
        "instruction": "Ecris is_operator qui retourne 1 si le caractere est un operateur shell.",
        "starterCode": "int is_operator(char c)\n{\n\t// | < > sont des operateurs\n}",
        "solution": "int is_operator(char c)\n{\n\treturn (c == '|' || c == '<' || c == '>');\n}",
        "hint": "Les operateurs sont |, < et >.",
        "difficulty": 1
      },
      {
        "id": 3,
        "title": "Extraire un mot",
        "instruction": "Ecris extract_word qui retourne le prochain mot (jusqu'a espace ou operateur).",
        "starterCode": "char *extract_word(char *line, int *i)\n{\n\tint start = *i;\n\t// Avance tant que pas espace ni operateur\n\t// Retourne une copie du mot\n}",
        "solution": "char *extract_word(char *line, int *i)\n{\n\tint start = *i;\n\twhile (line[*i] && line[*i] != ' ' && !is_operator(line[*i]))\n\t\t(*i)++;\n\treturn (strndup(line + start, *i - start));\n}",
        "hint": "Avance jusqu'a un espace ou operateur, puis strndup.",
        "difficulty": 2
      },
      {
        "id": 4,
        "title": "Extraire un operateur",
        "instruction": "Ecris extract_operator qui gere > et >>.",
        "starterCode": "char *extract_op(char *line, int *i)\n{\n\t// Gere |, <, >, >>\n}",
        "solution": "char *extract_op(char *line, int *i)\n{\n\tif (line[*i] == '>' && line[*i + 1] == '>')\n\t{\n\t\t*i += 2;\n\t\treturn (strdup(\">>\"));\n\t}\n\tchar op[2] = {line[*i], '\\0'};\n\t(*i)++;\n\treturn (strdup(op));\n}",
        "hint": "Verifie si c'est >> en regardant le caractere suivant.",
        "difficulty": 2
      },
      {
        "id": 5,
        "title": "Tokeniser une commande simple",
        "instruction": "Tokenise manuellement 'cat -n file | wc -l'.",
        "starterCode": "// cat -n file | wc -l\n// Tokens : ???",
        "solution": "// Tokens : 'cat', '-n', 'file', '|', 'wc', '-l'\n// 6 tokens : 4 WORD, 1 PIPE, 1 WORD",
        "hint": "Chaque mot et operateur est un token separe.",
        "difficulty": 1
      }
    ]
  },
  "starterCode": "#include <stdlib.h>\n#include <string.h>\n\n// A completer\n",
  "solution": "#include <stdlib.h>\n#include <string.h>\n\n// Solution complete de l'exercice\n",
  "hints": [
    "Parcours la chaine caractere par caractere en sautant les espaces.",
    "Verifie si le caractere courant est un operateur (|, <, >) avant d'extraire un mot.",
    "Pour >>, verifie le caractere suivant. Utilise strdup ou strndup pour creer les tokens."
  ],
  "testCases": [
    {
      "id": 1,
      "description": "Liste de tokens pour 'ls | grep test'",
      "stdin": "",
      "expectedStdout": "WORD:ls PIPE:| WORD:grep WORD:test\n",
      "expectedExitCode": 0,
      "visible": true
    },
    {
      "id": 2,
      "description": "Liste avec redirection",
      "stdin": "",
      "expectedStdout": "WORD:echo WORD:hi REDIR_OUT:> WORD:f.txt\n",
      "expectedExitCode": 0,
      "visible": false
    },
    {
      "id": 3,
      "description": "Liberation sans fuite",
      "stdin": "",
      "expectedStdout": "OK\n",
      "expectedExitCode": 0,
      "visible": false
    }
  ],
  "constraints": {
    "allowedFunctions": [
      "malloc",
      "free",
      "write",
      "strcmp",
      "strdup"
    ],
    "forbiddenFunctions": [
      "printf"
    ],
    "maxExecutionTime": 5000,
    "maxMemory": 128
  },
  "relatedExercises": [
    "c-day66-ex00-ft-tokenize",
    "c-day66-ex01-ft-token-type"
  ],
  "resources": [
    {
      "title": "Analyse lexicale - Introduction",
      "url": "https://en.wikipedia.org/wiki/Lexical_analysis",
      "type": "documentation"
    },
    {
      "title": "Ecrire un shell en C",
      "url": "https://www.geeksforgeeks.org/making-linux-shell-c/",
      "type": "article"
    }
  ]
}